{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140dc7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c124d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a4213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./FlagAlpha--Llama2-Chinese-7b-Chat/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,use_fast=False)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94c4fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff622917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa52543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca7f9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 12199], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<s>hello\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ed42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18c60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a02037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-20 16:44:48,646] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a90563735d14500b208bb7f3940d4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyd/miniconda3/envs/flexgen/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/wyd/miniconda3/envs/flexgen/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16)\n",
    "model = model.eval();\n",
    "model.to(\"cuda:0\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e6b3d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.Size([32000, 4096]) torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.0.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.0.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.0.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.1.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.1.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.1.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.1.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.2.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.2.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.2.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.2.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.3.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.3.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.3.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.3.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.4.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.4.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.4.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.4.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.5.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.5.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.5.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.5.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.5.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.5.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.5.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.6.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.6.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.6.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.6.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.6.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.6.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.6.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.7.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.7.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.7.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.7.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.7.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.7.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.7.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.8.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.8.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.8.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.8.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.8.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.8.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.8.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.9.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.9.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.9.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.9.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.9.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.9.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.9.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.10.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.10.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.10.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.10.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.10.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.10.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.10.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.11.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.11.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.11.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.11.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.11.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.11.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.11.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.12.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.12.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.12.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.12.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.12.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.12.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.12.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.13.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.13.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.13.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.13.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.13.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.13.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.13.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.14.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.14.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.14.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.14.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.14.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.14.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.14.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.15.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.15.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.15.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.15.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.15.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.15.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.15.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.16.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.16.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.16.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.16.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.16.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.16.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.16.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.17.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.17.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.17.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.17.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.17.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.17.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.17.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.18.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.18.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.18.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.18.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.18.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.18.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.18.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.19.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.19.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.19.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.19.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.19.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.19.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.19.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.20.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.20.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.20.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.20.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.20.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.20.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.20.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.21.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.21.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.21.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.21.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.21.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.21.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.21.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.22.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.22.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.22.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.22.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.22.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.22.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.22.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.23.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.23.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.23.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.23.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.23.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.23.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.23.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.24.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.24.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.24.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.24.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.24.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.24.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.24.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.25.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.25.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.25.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.25.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.25.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.25.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.25.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.26.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.26.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.26.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.26.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.26.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.26.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.26.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.27.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.27.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.27.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.27.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.27.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.27.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.27.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.28.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.28.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.28.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.28.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.28.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.28.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.28.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.28.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.28.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.29.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.29.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.29.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.29.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.29.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.29.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.29.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.29.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.29.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.30.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.30.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.30.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.30.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.30.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.30.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.30.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.30.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.30.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.31.self_attn.q_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.31.self_attn.k_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.31.self_attn.v_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.31.self_attn.o_proj.weight torch.Size([4096, 4096]) torch.float16\n",
      "model.layers.31.mlp.gate_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.31.mlp.up_proj.weight torch.Size([11008, 4096]) torch.float16\n",
      "model.layers.31.mlp.down_proj.weight torch.Size([4096, 11008]) torch.float16\n",
      "model.layers.31.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.layers.31.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.norm.weight torch.Size([4096]) torch.float16\n",
      "lm_head.weight torch.Size([32000, 4096]) torch.float16\n"
     ]
    }
   ],
   "source": [
    "for key,val in model.named_parameters():\n",
    "    print(key,val.shape,val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2643f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.984405458089668"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096*4096*3 /(512*(4096*3)+(4096*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d773f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36af393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(['<s>Human: 介绍一下中国\\n</s><s>Assistant: '], return_tensors=\"pt\",add_special_tokens=False).input_ids.to('cuda')        \n",
    "generate_input = {\n",
    "    \"input_ids\":input_ids,\n",
    "    \"max_new_tokens\":512,\n",
    "    \"do_sample\":True,\n",
    "    \"top_k\":50,\n",
    "    \"top_p\":0.95,\n",
    "    \"temperature\":0.3,\n",
    "    \"repetition_penalty\":1.3,\n",
    "    \"eos_token_id\":tokenizer.eos_token_id,\n",
    "    \"bos_token_id\":tokenizer.bos_token_id,\n",
    "    \"pad_token_id\":tokenizer.pad_token_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218e4c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyd/miniconda3/envs/flexgen/lib/python3.8/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Human: 介绍一下中国\n",
      "</s><s>Assistant: 作为世界上最大的人口和面积，历史悠久、文化丰富的中华民族在数千年来不断发展成长。现代社会中，我们正处于全球经济趋同工程时期，需要更加注重科技创新与高效管理等方面的实际运用能力。建设可持续性是当前所有行业都必须关心的问题之一，而对这个话题也提出了相应的解决思路。首先，通过改进生态保护政策并加速节能转变以及自然资源利用的深度开放；其次，加强基本教育水平和就业机会的广泛分配；再者，引导消费主体向健康、安全、环保三位一体的品牌选择，从而形成市场支持良好的商家群体。此外还包括多种合法手段如公共服务活动、志愿者组织参与、网络传播等，希望每一个人都能认真反省自身，到达“小事”的意义，给城乡居民增添美好的日常生活乐趣！\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "generate_ids  = model.generate(**generate_input)\n",
    "text = tokenizer.decode(generate_ids[0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f386f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./main -m ggml_output/ggml-model-q4_0.gguf -p \"<s>Human: 介绍一下中国\\n</s><s>Assistant: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7917e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-27 15:36:45,535] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
     ]
    }
   ],
   "source": [
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(\n",
    "    \"./gptq_output/\",\n",
    "    device=\"cuda:1\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605227b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2019129257, -2004318071, -2004318072,  ...,  1756867686,\n",
       "           678656169,  1537702536],\n",
       "        [-2006349400, -1986492536, -2022143864,  ..., -1759015642,\n",
       "         -1235646888,  2008529074],\n",
       "        [ 2054715255, -1853319016, -1886877576,  ..., -1734820422,\n",
       "          1478080180,  1486316939],\n",
       "        ...,\n",
       "        [-1847615302, -1478832996,     5714507,  ...,  2009618828,\n",
       "            -9982040,  -929388452],\n",
       "        [  469758001, -1510361463,  -977887862,  ..., -1392946315,\n",
       "          1829550008,  1035705504],\n",
       "        [ -258158699,  -146814948,  -930760287,  ...,  -645957253,\n",
       "           259539631, -1783313018]], device='cuda:1', dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.model.layers[0].self_attn.qkv_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6955d711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaGPTQForCausalLM(\n",
       "  (model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): FusedLlamaAttentionForQuantizedModel(\n",
       "            (qkv_proj): GeneralQuantLinear(in_features=4096, out_features=12288, bias=True)\n",
       "            (o_proj): GeneralQuantLinear(in_features=4096, out_features=4096, bias=True)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (act_fn): SiLUActivation()\n",
       "            (down_proj): GeneralQuantLinear(in_features=11008, out_features=4096, bias=True)\n",
       "            (gate_proj): GeneralQuantLinear(in_features=4096, out_features=11008, bias=True)\n",
       "            (up_proj): GeneralQuantLinear(in_features=4096, out_features=11008, bias=True)\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08d5020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.embed_tokens.weight torch.Size([32000, 4096]) torch.float16\n",
      "model.model.layers.0.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.0.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.0.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.0.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.0.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.0.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.0.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.0.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.0.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.0.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.0.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.0.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.1.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.1.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.1.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.1.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.1.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.1.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.1.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.1.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.1.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.1.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.1.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.1.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.2.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.2.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.2.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.2.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.2.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.2.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.2.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.2.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.2.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.2.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.2.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.2.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.3.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.3.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.3.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.3.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.3.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.3.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.3.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.3.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.3.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.3.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.3.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.3.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.4.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.4.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.4.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.4.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.4.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.4.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.4.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.4.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.4.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.4.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.4.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.4.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.5.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.5.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.5.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.5.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.5.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.5.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.5.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.5.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.5.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.5.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.5.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.5.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.6.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.6.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.6.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.6.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.6.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.6.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.6.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.6.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.6.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.6.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.6.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.6.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.7.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.7.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.7.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.7.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.7.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.7.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.7.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.7.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.7.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.7.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.7.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.7.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.8.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.8.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.8.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.8.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.8.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.8.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.8.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.8.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.8.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.8.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.8.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.8.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.9.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.9.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.9.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.9.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.9.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.9.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.9.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.9.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.9.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.9.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.9.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.9.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.10.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.10.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.10.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.10.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.10.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.10.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.10.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.10.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.10.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.10.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.10.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.10.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.11.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.11.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.11.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.11.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.11.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.11.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.11.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.11.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.11.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.11.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.11.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.11.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.12.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.12.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.12.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.12.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.12.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.12.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.12.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.12.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.12.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.12.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.12.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.12.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.13.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.13.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.13.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.13.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.13.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.13.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.13.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.13.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.13.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.13.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.13.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.13.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.14.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.14.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.14.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.14.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.14.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.14.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.14.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.14.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.14.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.14.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.14.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.14.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.15.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.15.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.15.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.15.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.15.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.15.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.15.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.15.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.15.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.15.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.15.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.15.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.16.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.16.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.16.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.16.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.16.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.16.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.16.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.16.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.16.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.16.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.16.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.16.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.17.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.17.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.17.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.17.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.17.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.17.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.17.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.17.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.17.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.17.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.17.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.17.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.18.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.18.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.18.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.18.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.18.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.18.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.18.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.18.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.18.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.18.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.18.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.18.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.19.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.19.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.19.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.19.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.19.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.19.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.19.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.19.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.19.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.19.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.19.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.19.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.20.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.20.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.20.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.20.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.20.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.20.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.20.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.20.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.20.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.20.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.20.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.20.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.21.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.21.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.21.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.21.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.21.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.21.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.21.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.21.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.21.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.21.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.21.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.21.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.22.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.22.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.22.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.22.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.22.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.22.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.22.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.22.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.22.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.22.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.22.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.22.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.23.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.23.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.23.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.23.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.23.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.23.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.23.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.23.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.23.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.23.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.23.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.23.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.24.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.24.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.24.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.24.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.24.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.24.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.24.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.24.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.24.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.24.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.24.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.24.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.25.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.25.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.25.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.25.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.25.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.25.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.25.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.25.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.25.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.25.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.25.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.25.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.26.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.26.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.26.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.26.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.26.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.26.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.26.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.26.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.26.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.26.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.26.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.26.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.27.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.27.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.27.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.27.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.27.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.27.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.27.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.27.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.27.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.27.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.27.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.27.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.28.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.28.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.28.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.28.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.28.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.28.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.28.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.28.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.28.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.28.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.28.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.28.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.29.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.29.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.29.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.29.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.29.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.29.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.29.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.29.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.29.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.29.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.29.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.29.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.30.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.30.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.30.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.30.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.30.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.30.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.30.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.30.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.30.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.30.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.30.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.30.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.31.self_attn.qkv_proj.weight torch.Size([512, 12288]) torch.int32\n",
      "model.model.layers.31.self_attn.qkv_proj.bias torch.Size([12288]) torch.float16\n",
      "model.model.layers.31.self_attn.o_proj.weight torch.Size([512, 4096]) torch.int32\n",
      "model.model.layers.31.self_attn.o_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.31.mlp.down_proj.weight torch.Size([1376, 4096]) torch.int32\n",
      "model.model.layers.31.mlp.down_proj.bias torch.Size([4096]) torch.float16\n",
      "model.model.layers.31.mlp.gate_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.31.mlp.gate_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.31.mlp.up_proj.weight torch.Size([512, 11008]) torch.int32\n",
      "model.model.layers.31.mlp.up_proj.bias torch.Size([11008]) torch.float16\n",
      "model.model.layers.31.input_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.layers.31.post_attention_layernorm.weight torch.Size([4096]) torch.float16\n",
      "model.model.norm.weight torch.Size([4096]) torch.float16\n",
      "model.lm_head.weight torch.Size([32000, 4096]) torch.float16\n"
     ]
    }
   ],
   "source": [
    "for key,val in model.named_parameters():\n",
    "    print(key,val.shape,val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(model.generate(\n",
    "    **tokenizer(\"<s>Human: 介绍一下中国\\n</s><s>Assistant: \", return_tensors=\"pt\").to(model.device))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0902c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
